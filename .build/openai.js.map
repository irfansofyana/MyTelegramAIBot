{
  "version": 3,
  "sources": ["../openai.ts"],
  "sourcesContent": ["import { Configuration, OpenAIApi } from 'openai';\n\nexport class MyOpenAI {\n  client: OpenAIApi;\n\n  constructor() {\n    const apiKey = process.env.OPENAI_API_KEY;\n    const configuration = new Configuration({\n      apiKey\n    });\n\n    this.client = new OpenAIApi(configuration);\n  }\n\n  public async writeCode(text: string): Promise<string> {\n    const response = await this.client.createCompletion({\n      model: 'code-davinci-002',\n      prompt: text,\n      temperature: 0,\n      top_p: 1.0,\n      frequency_penalty: 0.0,\n      presence_penalty: 0.0,\n      max_tokens: 300\n    });\n\n    return response.data.choices[0].text as string;\n  }\n\n  public async explainCode(code: string): Promise<string> {\n    code += `\\n\"\"\"\\n Here's what the above code is doing:\\n1. `\n    const response = await this.client.createCompletion({\n      model: 'code-davinci-002',\n      prompt: code,\n      temperature: 0,\n      top_p: 1.0,\n      frequency_penalty: 0.0,\n      presence_penalty: 0.0,\n      max_tokens: 300,\n      stop: [`\"\"\"`]\n    });\n\n    return response.data.choices[0].text as string;\n  }\n\n  public async tldr(text: string): Promise<string> {\n    text += \"\\nTl;dr\\n\";\n\n    const response = await this.client.createCompletion({\n      model: 'text-davinci-003',\n      prompt: text,\n      temperature: 0.7,\n      top_p: 1.0,\n      frequency_penalty: 0.0,\n      presence_penalty: 1.0,\n      max_tokens: 200,\n    });\n\n    return response.data.choices[0].text as string;\n  }\n\n  public async brainstorm(text: string): Promise<string> {\n    text += \"\\nLet's think step by step.\"\n\n    const response = await this.client.createCompletion({\n      model: 'text-davinci-003',\n      prompt: text,\n      temperature: 0.69,\n      max_tokens: 250,\n      top_p: 1,\n      frequency_penalty: 0.2,\n      presence_penalty: 0.57,\n      stop: [\"###\"],\n    });\n\n    return response.data.choices[0].text as string;\n  }\n\n  public async askRandom(text: string): Promise<string> {\n    const response = await this.client.createCompletion({\n      model: 'text-davinci-003',\n      prompt: text,\n      temperature: 0.7,\n      max_tokens: 250,\n      top_p: 1,\n      frequency_penalty: 0.5,\n      presence_penalty: 0.5\n    });\n\n    return response.data.choices[0].text as string || `I don't know the answer`;\n  }\n}"],
  "mappings": ";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAAyC;AAElC,MAAM,SAAS;AAAA,EACpB;AAAA,EAEA,cAAc;AACZ,UAAM,SAAS,QAAQ,IAAI;AAC3B,UAAM,gBAAgB,IAAI,4BAAc;AAAA,MACtC;AAAA,IACF,CAAC;AAED,SAAK,SAAS,IAAI,wBAAU,aAAa;AAAA,EAC3C;AAAA,EAEA,MAAa,UAAU,MAA+B;AACpD,UAAM,WAAW,MAAM,KAAK,OAAO,iBAAiB;AAAA,MAClD,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,YAAY;AAAA,IACd,CAAC;AAED,WAAO,SAAS,KAAK,QAAQ,GAAG;AAAA,EAClC;AAAA,EAEA,MAAa,YAAY,MAA+B;AACtD,YAAQ;AAAA;AAAA;AAAA;AACR,UAAM,WAAW,MAAM,KAAK,OAAO,iBAAiB;AAAA,MAClD,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,YAAY;AAAA,MACZ,MAAM,CAAC,KAAK;AAAA,IACd,CAAC;AAED,WAAO,SAAS,KAAK,QAAQ,GAAG;AAAA,EAClC;AAAA,EAEA,MAAa,KAAK,MAA+B;AAC/C,YAAQ;AAER,UAAM,WAAW,MAAM,KAAK,OAAO,iBAAiB;AAAA,MAClD,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,YAAY;AAAA,IACd,CAAC;AAED,WAAO,SAAS,KAAK,QAAQ,GAAG;AAAA,EAClC;AAAA,EAEA,MAAa,WAAW,MAA+B;AACrD,YAAQ;AAER,UAAM,WAAW,MAAM,KAAK,OAAO,iBAAiB;AAAA,MAClD,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,MAAM,CAAC,KAAK;AAAA,IACd,CAAC;AAED,WAAO,SAAS,KAAK,QAAQ,GAAG;AAAA,EAClC;AAAA,EAEA,MAAa,UAAU,MAA+B;AACpD,UAAM,WAAW,MAAM,KAAK,OAAO,iBAAiB;AAAA,MAClD,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,aAAa;AAAA,MACb,YAAY;AAAA,MACZ,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,IACpB,CAAC;AAED,WAAO,SAAS,KAAK,QAAQ,GAAG,QAAkB;AAAA,EACpD;AACF;",
  "names": []
}
